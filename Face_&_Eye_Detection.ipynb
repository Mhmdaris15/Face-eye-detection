{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Face & Eye Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mhmdaris15/Face-eye-detection/blob/main/Face_%26_Eye_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeZWKCiPlu6H"
      },
      "source": [
        "## Face & Eye Detection using HAAR Cascade Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2FN8EdFl2b2"
      },
      "source": [
        "from google.colab import files as colabfiles\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "T9qmY1lgmBGP",
        "outputId": "2bad950a-6c97-4ffb-c806-989e389779ad"
      },
      "source": [
        "filess = colabfiles.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e83d08ec-8b58-4731-beb5-cf1d1a8e1119\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e83d08ec-8b58-4731-beb5-cf1d1a8e1119\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Elon_Musk_2015.jpg to Elon_Musk_2015.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z37r8mjolu6b"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# We point OpenCV's CascadeClassifier function to where our \n",
        "# classifier (XML file format) is stored\n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load our image, resize and then convert it to grayscale\n",
        "image = cv2.imread('Elon_Musk_2015.jpg')\n",
        "scale_percent = 20 # percent of original size\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "image = cv2.resize(image, dsize=dim, fx=.5, fy=.5, interpolation=cv2.INTER_LANCZOS4)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Our classifier returns the ROI of the detected face as a tuple\n",
        "# It stores the top left coordinate and the bottom right coordiantes\n",
        "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "if faces is None:\n",
        "    print(\"No faces found\")\n",
        "\n",
        "# We iterate through our faces array and draw a rectangle\n",
        "# over each face in faces\n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
        "    cv2_imshow(image)\n",
        "    cv2.waitKey(0)\n",
        "    \n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO4UFAX6lu6f"
      },
      "source": [
        "### Let's combine face and eye detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC9AKNNAlu6g"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        " \n",
        "img = cv2.imread('Elon_Musk_2015.jpg')\n",
        "scale_percent = 20 # percent of original size\n",
        "width = int(img.shape[1] * scale_percent / 100)\n",
        "height = int(img.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "img = cv2.resize(img, dsize=dim, fx=.5, fy=.5, interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_classifier.detectMultiScale(gray, 1.5, 6)\n",
        "\n",
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "if faces is ():\n",
        "    print(\"No Face Found\")\n",
        "amountLoop = 0\n",
        "for (x,y,w,h) in faces:\n",
        "    \n",
        "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
        "    cv2_imshow(img)\n",
        "    cv2.waitKey(0)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        if amountLoop == 2 :\n",
        "          break\n",
        "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
        "        cv2_imshow(img)\n",
        "        cv2.waitKey(0)\n",
        "        amountLoop += 1\n",
        "    \n",
        "    \n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWvMMTrQlu6k"
      },
      "source": [
        "### Let's make a live face & eye detection, keeping the face inview at all times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdkcSuWxu1I8"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      // await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn0pLwi_u1I_"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2b649v7lu6l"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "def face_detector(img, size=0.5):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "    if faces is ():\n",
        "        return img\n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        x = x - 50\n",
        "        w = w + 50\n",
        "        y = y - 50\n",
        "        h = h + 50\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = img[y:y+h, x:x+w]\n",
        "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
        "        \n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2) \n",
        "            \n",
        "    roi_color = cv2.flip(roi_color,1)\n",
        "    return roi_color\n",
        "\n",
        "# while True:\n",
        "#   filename = take_photo()\n",
        "#   # cv2_imshow(face_detector('photo.jpg'))\n",
        "#   img = cv2.imread('photo.jpg')\n",
        "#   cv2_imshow(face_detector(img))\n",
        "#   if cv2.waitKey(1) == 13 :\n",
        "#     break\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    cv2_imshow(face_detector(frame))\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSwimxXtlu6n"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_clf = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_clf = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "def face_detector(image, size=1.5):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    face_corners = face_clf.detectMultiScale(gray, 1.4, 3)\n",
        "    if face_corners is None:\n",
        "        return image\n",
        "    for (x,y,w,h) in face_corners:\n",
        "        cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,254), 2)\n",
        "        roi_color = image[y:y+h, x:x+w]\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        eye_corners = eye_clf.detectMultiScale(roi_gray)\n",
        "        for (ex,ey,ew,eh) in eye_corners:\n",
        "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255,0,0), 2)\n",
        "            #cv2.circle(roi_color, (int((ex+ew)/2), int((ey+eh)/2)), 0, (255,0,0), 2)\n",
        "    roi_color = cv2.flip(roi_color, 1)\n",
        "    return roi_color\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    cv2_imshow(face_detector(frame))\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3cETf9jUlu6p"
      },
      "source": [
        "### Tuning Cascade Classifiers\n",
        "\n",
        "*ourClassifier*.**detectMultiScale**(input image, **Scale Factor** , **Min Neighbors**)\n",
        "\n",
        "- **Scale Factor**\n",
        "Specifies how much we reduce the image size each time we scale. E.g. in face detection we typically use 1.3. This means we reduce the image by 30% each time it’s scaled. Smaller values, like 1.05 will take longer to compute, but will increase the rate of detection.\n",
        "\n",
        "\n",
        "\n",
        "- **Min Neighbors**\n",
        "Specifies the number of neighbors each potential window should have in order to consider it a positive detection. Typically set between 3-6. \n",
        "It acts as sensitivity setting, low values will sometimes detect multiples faces over a single face. High values will ensure less false positives, but you may miss some faces.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jP1-PVlu6r",
        "outputId": "0d7b4c92-e8fb-4199-8e0e-1a6b35befbd7"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# cv2.namedWindow('Aris Resized', cv2.WINDOW_NORMAL)\n",
        "image = cv2.imread('../../../../../Downloads/files/aris-san.jpg', -1)\n",
        "imageS = cv2.resize(image, (int(image.shape[1]/2), int(image.shape[0]/2)))\n",
        "imageS = imageS[150:700, 175:700]\n",
        "gray = cv2.cvtColor(imageS, cv2.COLOR_BGR2GRAY)\n",
        "print(imageS.shape)\n",
        "cv2.imshow('Aris Grayed', gray)\n",
        "cv2.imshow('Aris Handsome', imageS)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "face_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
        "\n",
        "print(face_detector)\n",
        "\n",
        "face_corner = face_detector.detectMultiScale(gray, 1.4, 5)\n",
        "\n",
        "if face_corner is None:\n",
        "    print('No result found here')\n",
        "\n",
        "for (x,y,w,h) in face_corner:\n",
        "    cv2.rectangle(imageS, (x,y), (x+w, y+h), (0,0,255), 2)\n",
        "    cv2.imshow('Detected', imageS)\n",
        "    cv2.waitKey(0)\n",
        "    RoiGray = gray[y:y+h, x:x+w]\n",
        "    RoiColor = imageS[y:y+h, x:x+w]\n",
        "    eye_corner = eye_detector.detectMultiScale(RoiGray, 1.3, 5)\n",
        "    for (ex, ey, ew, eh) in eye_corner:\n",
        "        cv2.rectangle(RoiColor, (ex, ey), (ex+ew, ey+eh), (255,0,0), 3)\n",
        "        cv2.imshow('Final Image', imageS)\n",
        "        cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(550, 525, 3)\n",
            "<CascadeClassifier 0000008D609905D0>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}